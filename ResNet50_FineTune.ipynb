{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028218ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0c2dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad10raza/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ahmad10raza/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/ahmad10raza/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74b538f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582af3f",
   "metadata": {},
   "source": [
    "### Step 3: Freeze Early Layers (Optional, Feature Extraction Phase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb10c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d1a94",
   "metadata": {},
   "source": [
    "### Step 4: Modify the Final Fully Connected Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ef7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45542bca",
   "metadata": {},
   "source": [
    "### Step 5: Define Transforms (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36a173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cdc1e",
   "metadata": {},
   "source": [
    "### Step 6: Load Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ef56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('Data/train', transform=transforms)\n",
    "val_dataset = datasets.ImageFolder('Data/val', transform=transforms)\n",
    "\n",
    "train_load = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec7a1a",
   "metadata": {},
   "source": [
    "### Step 7: Set Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ddf6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c08bbcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] Loss: 0.3798\n",
      "Epoch [2/25] Loss: 0.1483\n",
      "Epoch [3/25] Loss: 0.2411\n",
      "Epoch [4/25] Loss: 0.1263\n",
      "Epoch [5/25] Loss: 0.1520\n",
      "Epoch [6/25] Loss: 0.1134\n",
      "Epoch [7/25] Loss: 0.2207\n",
      "Epoch [8/25] Loss: 0.1328\n",
      "Epoch [9/25] Loss: 0.0987\n",
      "Epoch [10/25] Loss: 0.0649\n",
      "Epoch [11/25] Loss: 0.2795\n",
      "Epoch [12/25] Loss: 0.1012\n",
      "Epoch [13/25] Loss: 0.2314\n",
      "Epoch [14/25] Loss: 0.2987\n",
      "Epoch [15/25] Loss: 0.1293\n",
      "Epoch [16/25] Loss: 0.0118\n",
      "Epoch [17/25] Loss: 0.0498\n",
      "Epoch [18/25] Loss: 0.1429\n",
      "Epoch [19/25] Loss: 0.1452\n",
      "Epoch [20/25] Loss: 0.1345\n",
      "Epoch [21/25] Loss: 0.0782\n",
      "Epoch [22/25] Loss: 0.3048\n",
      "Epoch [23/25] Loss: 0.2004\n",
      "Epoch [24/25] Loss: 0.0438\n",
      "Epoch [25/25] Loss: 0.1578\n"
     ]
    }
   ],
   "source": [
    "devices = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(devices)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, lables in train_load:\n",
    "        inputs, lables = inputs.to(devices), lables.to(devices)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,lables)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a1ec7",
   "metadata": {},
   "source": [
    "#### Step 9: Unfreeze Some Earlier Layers for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9417ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ac733",
   "metadata": {},
   "source": [
    "### Step 10: Use a Lower Learning Rate for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730918f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9aa206",
   "metadata": {},
   "source": [
    "### Step 11: Fine-Tune Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be152c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 0.2641\n",
      "Epoch [2/10] Loss: 0.1761\n",
      "Epoch [3/10] Loss: 0.0774\n",
      "Epoch [4/10] Loss: 0.1687\n",
      "Epoch [5/10] Loss: 0.0304\n",
      "Epoch [6/10] Loss: 0.1047\n",
      "Epoch [7/10] Loss: 0.1587\n",
      "Epoch [8/10] Loss: 0.1355\n",
      "Epoch [9/10] Loss: 0.0286\n",
      "Epoch [10/10] Loss: 0.1321\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # fine-tuning epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_load:\n",
    "        inputs, labels = inputs.to(devices), labels.to(devices)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7763677",
   "metadata": {},
   "source": [
    " ðŸš€ When you're fine-tuning **ResNet-50**, making the process **faster and more efficient** is key to saving both time and resources. Here are **best practices** to help speed up the fine-tuning process:\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ›  Best Practices to Fine-Tune Faster in ResNet-50\n",
    "\n",
    "### 1. **Use Pretrained Weights (Always!)**\n",
    "Always start with **pre-trained weights** from ImageNet, as they already contain useful knowledge that will speed up convergence. **This is the essence of transfer learning**.\n",
    "\n",
    "- **Don't train from scratch**, unless you absolutely need to.\n",
    "- In PyTorch, use `resnet50(pretrained=True)` to load pre-trained weights.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Start with Smaller Learning Rates**\n",
    "When fine-tuning, using a **smaller learning rate** initially ensures that you donâ€™t disrupt the learned features in the pre-trained model. \n",
    "\n",
    "- Start with a **low learning rate** like `1e-4` or `1e-5` for the first few epochs, then increase gradually if needed.\n",
    "- Use **learning rate scheduling** to adjust dynamically during training (e.g., **Cosine Annealing**, **One-Cycle Policy**).\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Use Gradual Unfreezing (Layer-wise Training)**\n",
    "Instead of unfreezing all layers at once, **unfreeze layers gradually** to avoid disturbing the pre-trained features.\n",
    "\n",
    "- **Start by freezing most layers**, then gradually **unfreeze the deeper layers** for fine-tuning.\n",
    "- Initially, fine-tune only the **last few layers** (like the fully connected layers) of ResNet-50. Then, progressively unfreeze more layers.\n",
    "- This allows the network to adapt better without overfitting early on.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Use Data Augmentation (Boosts Generalization and Speed)**\n",
    "Use **aggressive data augmentation** during training. This not only improves generalization but can **speed up convergence** because it helps the model learn more varied representations from the same data.\n",
    "\n",
    "Common augmentations:\n",
    "- **Random Horizontal Flip**\n",
    "- **Random Rotation**\n",
    "- **Random Cropping**\n",
    "- **Color Jitter (Brightness, Contrast, Saturation)**\n",
    "\n",
    "```python\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Use Mixed Precision Training**\n",
    "Mixed precision allows you to use **half-precision floats (FP16)** instead of single-precision (FP32), resulting in **faster training and lower memory usage** without sacrificing accuracy.\n",
    "\n",
    "- PyTorch supports this with **automatic mixed precision (AMP)**.\n",
    "- Use the `torch.cuda.amp` package to enable AMP in your training loop.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Inside training loop\n",
    "for inputs, labels in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast():  # Use mixed precision\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 6. **Use Faster Optimizers**\n",
    "Switch to **faster optimizers** like **AdamW** instead of regular **SGD**. AdamW adapts learning rates for each parameter, which can lead to **faster convergence**.\n",
    "\n",
    "- **AdamW** (instead of Adam or SGD) improves training stability and speeds up convergence.\n",
    "- Example:\n",
    "  ```python\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "  ```\n",
    "\n",
    "\n",
    "\n",
    "### 7. **Utilize Transfer Learning on Smaller Subsets First**\n",
    "Start by fine-tuning on a **small subset** of your training data. This helps you:\n",
    "- **Test your training pipeline** quickly.\n",
    "- Adjust hyperparameters without waiting for long epochs.\n",
    "- Identify issues and make sure everything is set up correctly before scaling up.\n",
    "\n",
    "\n",
    "\n",
    "### 8. **Use Multi-GPU (If Available)**\n",
    "If you have access to **multiple GPUs**, you can use **Data Parallelism** to speed up training by distributing the work across multiple GPUs.\n",
    "\n",
    "- In PyTorch, you can easily use `nn.DataParallel(model)` to parallelize the model across multiple GPUs.\n",
    "\n",
    "```python\n",
    "model = nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 9. **Early Stopping**\n",
    "Use **early stopping** to halt training when the model stops improving on the validation set. This saves time and prevents overfitting.\n",
    "\n",
    "- Track the **validation loss** and stop if it doesn't improve for a specified number of epochs.\n",
    "\n",
    "Example (simplified):\n",
    "```python\n",
    "# Define early stopping mechanism based on validation loss\n",
    "patience = 5  # how many epochs to wait before stopping\n",
    "counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train_epoch(model, optimizer, data_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    val_loss = validate(model, val_loader)\n",
    "\n",
    "    # Early stopping condition\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 10. **Reduce the Batch Size (If Memory Allows)**\n",
    "- If your GPU memory allows, reducing the **batch size** can help reduce training time per epoch.\n",
    "- This also allows more frequent updates to weights, speeding up convergence.\n",
    "\n",
    "However, **beware** of going too low on batch size since it might hurt training stability, so **find a balance**.\n",
    "\n",
    "\n",
    "\n",
    "### 11. **Use Learning Rate Finder**\n",
    "Before you start training, try using a **learning rate finder** to find the best starting learning rate.\n",
    "\n",
    "- Libraries like **fastai** offer a built-in learning rate finder that helps you identify the optimal learning rate quickly.\n",
    "\n",
    "\n",
    "\n",
    "# ðŸš€ Summary of Best Practices\n",
    "\n",
    "1. **Pre-trained weights** for faster convergence.\n",
    "2. Start with **smaller learning rates**.\n",
    "3. Use **gradual unfreezing** (start fine-tuning with only top layers).\n",
    "4. Apply **aggressive data augmentation**.\n",
    "5. Enable **mixed precision training**.\n",
    "6. Use **AdamW optimizer**.\n",
    "7. Fine-tune on **smaller subsets** first.\n",
    "8. Use **multi-GPU** (if available).\n",
    "9. Implement **early stopping**.\n",
    "10. Fine-tune with **optimal batch size**.\n",
    "11. Use **learning rate finder** to choose the best LR.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17991d5",
   "metadata": {},
   "source": [
    "## 1. Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c41743",
   "metadata": {},
   "source": [
    "### 1.1 Calculate Validation Accuracy\n",
    "You should check how well your model is generalizing to the unseen data in the validation set. Here's how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa42dcb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Get predicted class\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (correct \u001b[38;5;241m/\u001b[39m total) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Evaluation loop to calculate accuracy\n",
    "model.eval()  # Switch model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for images, labels in val_loader:  # val_loader is your validation data\n",
    "        images, labels = inputs.to(devices), labels.to(devices)\n",
    "        outputs = model(images)  # Get model predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d7f8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 99.82%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop to calculate accuracy\n",
    "model.eval()  # Switch model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for images, labels in val_loader:  # val_loader is your validation data\n",
    "        # Move data to the correct device\n",
    "        images, labels = images.to(devices), labels.to(devices)\n",
    "\n",
    "        outputs = model(images)  # Get model predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "        # Make sure to handle last batch size mismatch\n",
    "        batch_size = labels.size(0)  # Size of the current batch (can be smaller for the last batch)\n",
    "        total += batch_size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e2345",
   "metadata": {},
   "source": [
    "## 1.2 Plot Loss and Accuracy Graphs\n",
    "Visualize the training and validation loss/accuracy over epochs to identify overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've saved loss values for each epoch in lists `train_loss` and `val_loss`\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train Loss')\n",
    "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "478ab4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of epoch losses (from your output)\n",
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "losses = [0.2641, 0.1761, 0.0774, 0.1687, 0.0304, 0.1047, 0.1587, 0.1355, 0.0286, 0.1321]\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Plotting the Loss Graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, losses, marker='o', color='b', label='Training Loss')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Training Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Displaying legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e89f31",
   "metadata": {},
   "source": [
    "## 2. Save the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6ea399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'resnet50_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model.load_state_dict(torch.load('resnet50_finetuned.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78865ca",
   "metadata": {},
   "source": [
    "## 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdeb92f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m img \u001b[38;5;241m=\u001b[39m transforms(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Apply the same transformations used for training\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(devices)\n\u001b[1;32m     14\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aiml-test/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Example for predicting a new image\n",
    "from PIL import Image\n",
    "img = Image.open('Data/val/n01440764/n01440764_36.JPEG')\n",
    "img = transforms(img).unsqueeze(0)  # Apply the same transformations used for training\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "   \n",
    "    output = model(img)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print(f'Predicted Class: {predicted.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e93631",
   "metadata": {},
   "source": [
    "### 4.1 Try Learning Rate Scheduling\n",
    "Since you observed some fluctuations, adjusting the learning rate dynamically during training can help stabilize learning. Common strategies include Cosine Annealing or One-Cycle Learning Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008dc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)  # T_max = total number of epochs\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_epoch()  # your training loop\n",
    "    scheduler.step()  # Update learning rate at the end of each epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a957ffe",
   "metadata": {},
   "source": [
    "### 4.2 Implement Early Stopping\n",
    "Monitor validation loss during training and stop training early if it doesnâ€™t improve for a set number of epochs. This prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ee7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 5  # Stop after 5 epochs without improvement\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_epoch()  # Your training loop\n",
    "    val_loss = validate_model()  # Compute validation loss\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfa5d7",
   "metadata": {},
   "source": [
    "## 5. Deploy the Model\n",
    "Once you're satisfied with the modelâ€™s performance, itâ€™s time to deploy it to serve predictions in a real-world application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851ed5b",
   "metadata": {},
   "source": [
    "### 5.1 Convert to TorchScript (for production)\n",
    "TorchScript allows you to run the model in C++ environments, on mobile, or in any framework that can load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TorchScript\n",
    "model.eval()  # Make sure to set the model to evaluation mode\n",
    "scripted_model = torch.jit.script(model)  # Or `torch.jit.trace(model, example_input)`\n",
    "\n",
    "# Save the TorchScript model\n",
    "scripted_model.save('resnet50_finetuned.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32770983",
   "metadata": {},
   "source": [
    "### 5.2 Serve the Model with a Web Framework (like Flask or FastAPI)\n",
    "To create a web service around your model, you can use frameworks like Flask or FastAPI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model\n",
    "model = resnet50(pretrained=False)\n",
    "model.load_state_dict(torch.load('resnet50_finetuned.pth'))\n",
    "model.eval()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Read image from POST request\n",
    "    img_data = request.files['image'].read()\n",
    "    img = Image.open(io.BytesIO(img_data)).convert('RGB')\n",
    "\n",
    "    # Apply same transformations\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return jsonify({'class': predicted.item()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
